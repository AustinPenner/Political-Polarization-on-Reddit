{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "import pprint\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import bz2,shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url_source='https://files.pushshift.io/reddit/comments/'):\n",
    "    \"Gets download links to all reddit comments by month\"\n",
    "\n",
    "    source = urllib.request.urlopen(url_source).read()\n",
    "    soup = bs.BeautifulSoup(source,'lxml')\n",
    "    table = soup.table\n",
    "\n",
    "    url_dict = {'month': [], 'link': []}\n",
    "    for i in table.find_all('tr', class_='file'):\n",
    "        rel_url = i.find('a').text\n",
    "        if rel_url[:2] == 'RC':\n",
    "            dot = rel_url.find('.')\n",
    "            url_dict['month'].append(rel_url[3:dot])\n",
    "            url_dict['link'].append(url_source + rel_url)\n",
    "    \n",
    "    return url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get download links from website and save to csv\n",
    "\n",
    "# download_links = get_links()\n",
    "# links_df = pd.DataFrame(download_links)\n",
    "# links_df.to_csv('comment_files/links_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-12</td>\n",
       "      <td>https://files.pushshift.io/reddit/comments/RC_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01</td>\n",
       "      <td>https://files.pushshift.io/reddit/comments/RC_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-02</td>\n",
       "      <td>https://files.pushshift.io/reddit/comments/RC_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-03</td>\n",
       "      <td>https://files.pushshift.io/reddit/comments/RC_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04</td>\n",
       "      <td>https://files.pushshift.io/reddit/comments/RC_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month                                               link\n",
       "0  2005-12  https://files.pushshift.io/reddit/comments/RC_...\n",
       "1  2006-01  https://files.pushshift.io/reddit/comments/RC_...\n",
       "2  2006-02  https://files.pushshift.io/reddit/comments/RC_...\n",
       "3  2006-03  https://files.pushshift.io/reddit/comments/RC_...\n",
       "4  2006-04  https://files.pushshift.io/reddit/comments/RC_..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve download links\n",
    "\n",
    "links_df = pd.read_csv('comment_files/links_dataframe.csv', )\n",
    "links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./comment_files/RC_2011-08.bz2', <http.client.HTTPMessage at 0x7fb12202b790>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_file(base_url, filename):\n",
    "    urllib.request.urlretrieve(base_url, './comment_files/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month                                              2011-08\n",
      "link     https://files.pushshift.io/reddit/comments/RC_...\n",
      "Name: 68, dtype: object\n",
      "month                                              2011-09\n",
      "link     https://files.pushshift.io/reddit/comments/RC_...\n",
      "Name: 69, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for _, row in links_df.iloc[68:70].iterrows():\n",
    "    url \n",
    "#     print(type(row))\n",
    "\n",
    "# url = url_dict['2011-08']\n",
    "# filename = url[url.rfind('/') + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileout = filename[:filename.find('.')] + '.json'\n",
    "\n",
    "with bz2.BZ2File('./comment_files/' + filename) as fr, open('./comment_files/' + fileout,'wb') as fw:\n",
    "    shutil.copyfileobj(fr,fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THIS ERRED OUT, AND ISN'T RECOMMENDED BECAUSE IT'S SLOWER THAN THE\n",
    "# COMMAND LINE MONGOIMPORT\n",
    "\n",
    "\n",
    "# db = client['reddit']\n",
    "# comments = db['comments']\n",
    "\n",
    "# with open('./comment_files/' + fileout) as f:\n",
    "#     file_data = json.load(f)\n",
    "\n",
    "# comments.insert_many(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
